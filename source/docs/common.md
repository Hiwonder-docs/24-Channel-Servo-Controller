  # Common.py API æ¥å£è¯´æ˜æ–‡æ¡£

  ## ğŸ“‹ ç›®å½•

- [æ¦‚è¿°](#æ¦‚è¿°)
- [ä¾èµ–åº“](#ä¾èµ–åº“)
- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [API æ¥å£è¯¦ç»†è¯´æ˜](#api-æ¥å£è¯¦ç»†è¯´æ˜)
- [é¢œè‰²å®šä¹‰å¸¸é‡](#1-é¢œè‰²å®šä¹‰å¸¸é‡)
- [æ—¥å¿—è¾“å‡ºå‡½æ•°](#2-æ—¥å¿—è¾“å‡ºå‡½æ•°)
- [å›¾åƒè½¬æ¢å‡½æ•°](#3-å›¾åƒè½¬æ¢å‡½æ•°)
- [é…ç½®æ–‡ä»¶å¤„ç†å‡½æ•°](#4-é…ç½®æ–‡ä»¶å¤„ç†å‡½æ•°)
- [å›¾åƒå¤„ç†å‡½æ•°](#5-å›¾åƒå¤„ç†å‡½æ•°)
- [é¢œè‰²ç®¡ç†ç±»](#6-é¢œè‰²ç®¡ç†ç±»)
- [å›¾åƒæ ‡æ³¨å‡½æ•°](#7-å›¾åƒæ ‡æ³¨å‡½æ•°)
- [å‡ ä½•è®¡ç®—å‡½æ•°](#8-å‡ ä½•è®¡ç®—å‡½æ•°)
- [å§¿æ€å˜æ¢å‡½æ•°](#9-å§¿æ€å˜æ¢å‡½æ•°)
- [çŸ©é˜µå˜æ¢å‡½æ•°](#10-çŸ©é˜µå˜æ¢å‡½æ•°)
- [ä½¿ç”¨ç¤ºä¾‹](#ä½¿ç”¨ç¤ºä¾‹)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [æ³¨æ„äº‹é¡¹](#æ³¨æ„äº‹é¡¹)
- [ç‰ˆæœ¬ä¿¡æ¯](#ç‰ˆæœ¬ä¿¡æ¯)
- [æ›´æ–°æ—¥å¿—](#æ›´æ–°æ—¥å¿—)

## ğŸ“– æ¦‚è¿°

`common.py` æ˜¯ä¸€ä¸ªä¸“ä¸ºROSæœºå™¨äººç³»ç»Ÿè®¾è®¡çš„é€šç”¨å·¥å…·å‡½æ•°åº“ï¼Œæä¾›äº†å›¾åƒå¤„ç†ã€åæ ‡å˜æ¢ã€æ•°å­¦è®¡ç®—ç­‰å¸¸ç”¨åŠŸèƒ½çš„APIæ¥å£ã€‚è¯¥æ¨¡å—ä¸»è¦ç”¨äºROSæœºå™¨äººç³»ç»Ÿä¸­çš„æ•°æ®å¤„ç†å’Œè½¬æ¢æ“ä½œï¼Œå…·æœ‰é«˜æ•ˆã€ç¨³å®šã€æ˜“ç”¨çš„ç‰¹ç‚¹ã€‚

### âœ¨ ä¸»è¦ç‰¹æ€§

- ğŸ–¼ï¸ **å›¾åƒå¤„ç†**: æ”¯æŒOpenCVä¸ROSå›¾åƒæ ¼å¼è½¬æ¢
- ğŸ”„ **åæ ‡å˜æ¢**: æä¾›å››å…ƒæ•°ã€æ¬§æ‹‰è§’ã€å˜æ¢çŸ©é˜µé—´çš„ç›¸äº’è½¬æ¢
- ğŸ“ **å‡ ä½•è®¡ç®—**: åŒ…å«è·ç¦»è®¡ç®—ã€è§’åº¦è®¡ç®—ã€åæ ‡æ˜ å°„ç­‰åŠŸèƒ½
- âš™ï¸ **é…ç½®ç®¡ç†**: æ”¯æŒYAMLé…ç½®æ–‡ä»¶çš„è¯»å†™æ“ä½œ
- ğŸ¨ **å¯è§†åŒ–**: æä¾›å›¾åƒæ ‡æ³¨å’Œé¢œè‰²ç®¡ç†åŠŸèƒ½

## ğŸ“¦ ä¾èµ–åº“

```python
import cv2          # OpenCVå›¾åƒå¤„ç†åº“ (>=4.0.0)
import math         # Pythonæ•°å­¦åº“
import yaml         # YAMLé…ç½®æ–‡ä»¶å¤„ç† (>=5.0)
import rospy        # ROS Pythonå®¢æˆ·ç«¯åº“
import numpy as np  # æ•°å€¼è®¡ç®—åº“ (>=1.19.0)
import transforms3d # 3Då˜æ¢åº“ (>=0.3.0)
import random       # éšæœºæ•°ç”Ÿæˆåº“
```

### å®‰è£…ä¾èµ–
```bash
pip install opencv-python numpy pyyaml transforms3d
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬å¯¼å…¥
```python
from sdk.common import cv2_image2ros, qua2rpy, distance, loginfo

# ä½¿ç”¨æ—¥å¿—åŠŸèƒ½
loginfo("ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")

# è®¡ç®—ä¸¤ç‚¹è·ç¦»
dist = distance((0, 0), (3, 4))  # è¿”å› 5.0
```

### å›¾åƒå¤„ç†ç¤ºä¾‹
```python
import cv2
from sdk.common import cv2_image2ros, get_area_max_contour

# è¯»å–å›¾åƒå¹¶è½¬æ¢ä¸ºROSæ ¼å¼
image = cv2.imread("test.jpg")
ros_image = cv2_image2ros(image, "camera_frame")

# æŸ¥æ‰¾æœ€å¤§è½®å»“
contours, _ = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
max_contour, area = get_area_max_contour(contours, threshold=100)
```

## ğŸ“š API æ¥å£è¯¦ç»†è¯´æ˜

### 1. é¢œè‰²å®šä¹‰å¸¸é‡

#### `range_rgb` å­—å…¸
å®šä¹‰äº†å¸¸ç”¨é¢œè‰²çš„BGRå€¼èŒƒå›´ï¼Œç”¨äºå›¾åƒå¤„ç†ä¸­çš„é¢œè‰²è¯†åˆ«å’Œè¿‡æ»¤ã€‚

```python
range_rgb = {
    'red': (0, 50, 255),      # çº¢è‰²èŒƒå›´
    'blue': (255, 50, 0),     # è“è‰²èŒƒå›´
    'green': (50, 255, 0),    # ç»¿è‰²èŒƒå›´
    'black': (0, 0, 0),       # é»‘è‰²
    'white': (255, 255, 255), # ç™½è‰²
}
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from sdk.common import range_rgb

# è·å–çº¢è‰²èŒƒå›´
red_range = range_rgb['red']  # (0, 50, 255)

# åœ¨å›¾åƒå¤„ç†ä¸­ä½¿ç”¨
lower_red = np.array([0, 50, 50])
upper_red = np.array([10, 255, 255])
```

### 2. æ—¥å¿—è¾“å‡ºå‡½æ•°

#### `loginfo(msg)`
è¾“å‡ºå¸¦é¢œè‰²çš„ROSæ—¥å¿—ä¿¡æ¯ï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§ã€‚

**å‚æ•°ï¼š**
- `msg` (str): è¦è¾“å‡ºçš„æ¶ˆæ¯å†…å®¹

**è¿”å›å€¼ï¼š** æ— 

**ç¤ºä¾‹ï¼š**
```python
from sdk.common import loginfo

loginfo("æœºå™¨äººå¯åŠ¨æˆåŠŸ")
loginfo("æ£€æµ‹åˆ°ç›®æ ‡ç‰©ä½“")
loginfo("åæ ‡è½¬æ¢å®Œæˆ")
```

### 3. å›¾åƒè½¬æ¢å‡½æ•°

#### `cv2_image2ros(image, frame_id='')`
å°†OpenCVå›¾åƒè½¬æ¢ä¸ºROS Imageæ¶ˆæ¯æ ¼å¼ã€‚

**å‚æ•°ï¼š**
- `image` (numpy.ndarray): OpenCVæ ¼å¼çš„å›¾åƒæ•°æ®
- `frame_id` (str): åæ ‡ç³»IDï¼Œé»˜è®¤ä¸ºç©ºå­—ç¬¦ä¸²

**è¿”å›å€¼ï¼š** ROS Imageæ¶ˆæ¯å¯¹è±¡

**ç¤ºä¾‹ï¼š**

```python
import cv2
from sdk.common import cv2_image2ros

# è¯»å–å›¾åƒ
image = cv2.imread("camera_image.jpg")

# è½¬æ¢ä¸ºROSæ ¼å¼
ros_img = cv2_image2ros(image, "camera_frame")

# å‘å¸ƒåˆ°ROSè¯é¢˜
pub = rospy.Publisher('/camera/image_raw', Image, queue_size=10)
pub.publish(ros_img)
```

#### `bgr8_to_jpeg(value, quality=75)`
å°†BGR8æ ¼å¼çš„å›¾åƒæ•°æ®è½¬æ¢ä¸ºJPEGæ ¼å¼ã€‚

**å‚æ•°ï¼š**

- `value` (numpy.ndarray): åŸå§‹BGR8æ ¼å¼å›¾åƒæ•°æ®
- `quality` (int): JPEGè´¨é‡ï¼ŒèŒƒå›´1-100ï¼Œé»˜è®¤75

**è¿”å›å€¼ï¼š** JPEGæ ¼å¼çš„å­—èŠ‚æ•°æ®

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import bgr8_to_jpeg

# è½¬æ¢å›¾åƒæ ¼å¼
jpeg_data = bgr8_to_jpeg(image, quality=90)

# ä¿å­˜ä¸ºæ–‡ä»¶
with open("output.jpg", "wb") as f:
    f.write(jpeg_data)
```

### 4. é…ç½®æ–‡ä»¶å¤„ç†å‡½æ•°

#### `get_yaml_data(yaml_file)`
è¯»å–YAMLé…ç½®æ–‡ä»¶å¹¶è¿”å›è§£æåçš„æ•°æ®ã€‚

**å‚æ•°ï¼š**

- `yaml_file` (str): YAMLæ–‡ä»¶è·¯å¾„

**è¿”å›å€¼ï¼š** è§£æåçš„é…ç½®æ•°æ®

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import get_yaml_data

# è¯»å–é…ç½®æ–‡ä»¶
config = get_yaml_data("robot_config.yaml")

# ä½¿ç”¨é…ç½®æ•°æ®
robot_name = config['robot_name']
max_speed = config['max_speed']
```

#### `save_yaml_data(data, yaml_file)`

å°†æ•°æ®ä¿å­˜ä¸ºYAMLæ ¼å¼æ–‡ä»¶ã€‚

**å‚æ•°ï¼š**

- `data` (dict): è¦ä¿å­˜çš„æ•°æ®
- `yaml_file` (str): ç›®æ ‡YAMLæ–‡ä»¶è·¯å¾„

**è¿”å›å€¼ï¼š** æ— 

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import save_yaml_data

# å‡†å¤‡é…ç½®æ•°æ®
config_data = {
    'robot_name': 'my_robot',
    'max_speed': 1.5,
    'sensors': ['camera', 'lidar', 'imu']
}

# ä¿å­˜é…ç½®æ–‡ä»¶
save_yaml_data(config_data, "new_config.yaml")
```

### 5. å›¾åƒå¤„ç†å‡½æ•°

#### `get_area_max_contour(contours, threshold=50)`

è·å–è½®å»“åˆ—è¡¨ä¸­é¢ç§¯æœ€å¤§çš„è½®å»“ï¼Œå¹¶è¿‡æ»¤æ‰é¢ç§¯è¿‡å°çš„è½®å»“ã€‚

**å‚æ•°ï¼š**

- `contours` (list): è½®å»“åˆ—è¡¨
- `threshold` (int): é¢ç§¯é˜ˆå€¼ï¼Œé»˜è®¤50

**è¿”å›å€¼ï¼š** å…ƒç»„ (æœ€å¤§è½®å»“, æœ€å¤§é¢ç§¯)

**ç¤ºä¾‹ï¼š**

```python
import cv2
from sdk.common import get_area_max_contour

# æŸ¥æ‰¾è½®å»“
contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

# è·å–æœ€å¤§è½®å»“
max_contour, max_area = get_area_max_contour(contours, threshold=100)

if max_contour is not None:
    # ç»˜åˆ¶æœ€å¤§è½®å»“
    cv2.drawContours(image, [max_contour], -1, (0, 255, 0), 2)
    print(f"æœ€å¤§è½®å»“é¢ç§¯: {max_area}")
```

#### `warp_affine(image, points, scale=1.0)`

å¯¹å›¾åƒè¿›è¡Œä»¿å°„å˜æ¢ï¼Œä½¿ä¸¤ç‚¹è¿çº¿æ°´å¹³å¯¹é½ã€‚

**å‚æ•°ï¼š**
- `image` (numpy.ndarray): è¾“å…¥å›¾åƒ
- `points` (tuple): ä¸¤ä¸ªç‚¹çš„åæ ‡ ((x1, y1), (x2, y2))
- `scale` (float): ç¼©æ”¾æ¯”ä¾‹ï¼Œé»˜è®¤1.0

**è¿”å›å€¼ï¼š** å˜æ¢åçš„å›¾åƒ

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import warp_affine

# äººè„¸å¯¹é½ç¤ºä¾‹
face_image = cv2.imread("face.jpg")
eye_points = ((100, 120), (150, 125))  # ä¸¤çœ¼åæ ‡

# å¯¹é½å›¾åƒ
aligned_face = warp_affine(face_image, eye_points, scale=1.0)
cv2.imwrite("aligned_face.jpg", aligned_face)
```

### 6. é¢œè‰²ç®¡ç†ç±»

#### `Colors` ç±»

æä¾›Ultralyticsé¢œè‰²è°ƒè‰²æ¿ï¼Œç”¨äºå›¾åƒæ ‡æ³¨å’Œå¯è§†åŒ–ã€‚

**æ–¹æ³•ï¼š**

- `__call__(i, bgr=False)`: è·å–æŒ‡å®šç´¢å¼•çš„é¢œè‰²
- `hex2rgb(h)`: å°†åå…­è¿›åˆ¶é¢œè‰²è½¬æ¢ä¸ºRGBå…ƒç»„

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import Colors

# åˆ›å»ºé¢œè‰²å®ä¾‹
colors = Colors()

# è·å–é¢œè‰²
color1 = colors(0)      # è·å–ç¬¬ä¸€ä¸ªé¢œè‰² (RGBæ ¼å¼)
color2 = colors(1, bgr=True)  # è·å–ç¬¬äºŒä¸ªé¢œè‰² (BGRæ ¼å¼)

# ç»˜åˆ¶ä¸åŒé¢œè‰²çš„è¾¹ç•Œæ¡†
for i, box in enumerate(boxes):
    color = colors(i)
    cv2.rectangle(image, box[0], box[1], color, 2)
```

### 7. å›¾åƒæ ‡æ³¨å‡½æ•°

#### `plot_one_box(x, img, color=None, label=None, line_thickness=None)`

åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†å’Œæ ‡ç­¾ã€‚

**å‚æ•°ï¼š**

- `x` (list): è¾¹ç•Œæ¡†åæ ‡ [x1, y1, x2, y2]
- `img` (numpy.ndarray): ç›®æ ‡å›¾åƒ
- `color` (tuple): ç»˜åˆ¶é¢œè‰²ï¼Œé»˜è®¤éšæœº
- `label` (str): æ ‡ç­¾æ–‡æœ¬
- `line_thickness` (int): çº¿æ¡ç²—ç»†

**è¿”å›å€¼ï¼š** æ— 

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import plot_one_box, Colors

# åˆ›å»ºé¢œè‰²å®ä¾‹
colors = Colors()

# ç»˜åˆ¶è¾¹ç•Œæ¡†
box = [100, 100, 200, 200]
plot_one_box(box, image, color=colors(0), label="Person", line_thickness=2)

# æ‰¹é‡ç»˜åˆ¶
for i, detection in enumerate(detections):
    box = detection['bbox']
    label = f"{detection['class']}: {detection['confidence']:.2f}"
    plot_one_box(box, image, color=colors(i), label=label)
```

### 8. å‡ ä½•è®¡ç®—å‡½æ•°

#### `distance(point_1, point_2)`

è®¡ç®—ä¸¤ç‚¹é—´çš„æ¬§å‡ é‡Œå¾—è·ç¦»ã€‚

**å‚æ•°ï¼š**

- `point_1` (tuple): ç¬¬ä¸€ä¸ªç‚¹åæ ‡ (x1, y1)
- `point_2` (tuple): ç¬¬äºŒä¸ªç‚¹åæ ‡ (x2, y2)

**è¿”å›å€¼ï¼š** ä¸¤ç‚¹é—´è·ç¦» (float)

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import distance

# è®¡ç®—è·ç¦»
dist = distance((0, 0), (3, 4))  # è¿”å› 5.0
dist = distance((10, 20), (15, 25))  # è¿”å› 7.07...

# åœ¨æœºå™¨äººå¯¼èˆªä¸­ä½¿ç”¨
robot_pos = (x, y)
target_pos = (target_x, target_y)
remaining_distance = distance(robot_pos, target_pos)
```

#### `box_center(box)`

è®¡ç®—è¾¹ç•Œæ¡†çš„ä¸­å¿ƒç‚¹ã€‚

**å‚æ•°ï¼š**

- `box` (list): è¾¹ç•Œæ¡†åæ ‡ (x1, y1, x2, y2)

**è¿”å›å€¼ï¼š** ä¸­å¿ƒç‚¹åæ ‡ (tuple)

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import box_center

# è®¡ç®—è¾¹ç•Œæ¡†ä¸­å¿ƒ
box = [100, 100, 200, 200]
center = box_center(box)  # è¿”å› (150.0, 150.0)

# åœ¨ç›®æ ‡è·Ÿè¸ªä¸­ä½¿ç”¨
for detection in detections:
    bbox = detection['bbox']
    center_point = box_center(bbox)
    print(f"ç›®æ ‡ä¸­å¿ƒ: {center_point}")
```

#### `point_remapped(point, now, new, data_type=float)`

å°†ç‚¹åæ ‡ä»ä¸€ä¸ªå›¾åƒå°ºå¯¸æ˜ å°„åˆ°å¦ä¸€ä¸ªå›¾åƒå°ºå¯¸ã€‚

**å‚æ•°ï¼š**
- `point` (tuple): åŸå§‹ç‚¹åæ ‡ (x, y)
- `now` (tuple): å½“å‰å›¾åƒå°ºå¯¸ (width, height)
- `new` (tuple): æ–°å›¾åƒå°ºå¯¸ (width, height)
- `data_type` (type): è¿”å›æ•°æ®ç±»å‹ï¼Œé»˜è®¤float

**è¿”å›å€¼ï¼š** æ˜ å°„åçš„ç‚¹åæ ‡

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import point_remapped

# åæ ‡æ˜ å°„
original_point = (100, 100)
original_size = (640, 480)
new_size = (1280, 960)

new_point = point_remapped(original_point, original_size, new_size)
# è¿”å› (200.0, 200.0)

# åœ¨å›¾åƒç¼©æ”¾ä¸­ä½¿ç”¨
resized_image = cv2.resize(image, new_size)
keypoints = [point_remapped(p, original_size, new_size) for p in original_keypoints]
```

#### `vector_2d_angle(v1, v2)`

è®¡ç®—ä¸¤ä¸ª2Då‘é‡é—´çš„å¤¹è§’ã€‚

**å‚æ•°ï¼š**
- `v1` (list/numpy.ndarray): ç¬¬ä¸€ä¸ªå‘é‡
- `v2` (list/numpy.ndarray): ç¬¬äºŒä¸ªå‘é‡

**è¿”å›å€¼ï¼š** å¤¹è§’ï¼ˆåº¦ï¼‰ï¼ŒèŒƒå›´ -180 åˆ° 180

**ç¤ºä¾‹ï¼š**

```python
import numpy as np
from sdk.common import vector_2d_angle

# è®¡ç®—å‘é‡å¤¹è§’
v1 = np.array([1, 0])
v2 = np.array([0, 1])
angle = vector_2d_angle(v1, v2)  # è¿”å› 90.0

# åœ¨æœºå™¨äººè½¬å‘ä¸­ä½¿ç”¨
current_direction = np.array([robot_vx, robot_vy])
target_direction = np.array([target_vx, target_vy])
turn_angle = vector_2d_angle(current_direction, target_direction)
```

### 9. å§¿æ€å˜æ¢å‡½æ•°

#### `qua2rpy(*qua)`

å°†å››å…ƒæ•°è½¬æ¢ä¸ºæ¬§æ‹‰è§’ï¼ˆRoll-Pitch-Yawï¼‰ã€‚

**å‚æ•°ï¼š**

- `qua`: å››å…ƒæ•°ï¼Œå¯ä»¥æ˜¯ROS Quaternionå¯¹è±¡æˆ–å››å…ƒæ•°æ•°ç»„ [x, y, z, w]

**è¿”å›å€¼ï¼š** æ¬§æ‹‰è§’å…ƒç»„ (roll, pitch, yaw)

**ç¤ºä¾‹ï¼š**

```python
import math
from sdk.common import qua2rpy

# ä»ROS Quaternionè½¬æ¢
from geometry_msgs.msg import Quaternion
quat = Quaternion()
quat.x, quat.y, quat.z, quat.w = 0, 0, 0, 1
roll, pitch, yaw = qua2rpy(quat)

# ä»æ•°ç»„è½¬æ¢
quat_array = [0, 0, 0, 1]  # å•ä½å››å…ƒæ•°
roll, pitch, yaw = qua2rpy(*quat_array)

# è½¬æ¢ä¸ºåº¦æ•°
roll_deg = math.degrees(roll)
pitch_deg = math.degrees(pitch)
yaw_deg = math.degrees(yaw)
```

#### `rpy2qua(roll, pitch, yaw)`

å°†æ¬§æ‹‰è§’è½¬æ¢ä¸ºå››å…ƒæ•°ã€‚

**å‚æ•°ï¼š**

- `roll` (float): æ»šè½¬è§’ï¼ˆå¼§åº¦ï¼‰
- `pitch` (float): ä¿¯ä»°è§’ï¼ˆå¼§åº¦ï¼‰
- `yaw` (float): åèˆªè§’ï¼ˆå¼§åº¦ï¼‰

**è¿”å›å€¼ï¼š** ROS Quaternionå¯¹è±¡

**ç¤ºä¾‹ï¼š**

```python
import math
from sdk.common import rpy2qua

# æ¬§æ‹‰è§’è½¬å››å…ƒæ•°
roll = 0
pitch = 0
yaw = math.pi/2  # 90åº¦åèˆªè§’

quat = rpy2qua(roll, pitch, yaw)

# åœ¨ROSæ¶ˆæ¯ä¸­ä½¿ç”¨
from geometry_msgs.msg import PoseStamped
pose_msg = PoseStamped()
pose_msg.pose.orientation = quat
```

### 10. çŸ©é˜µå˜æ¢å‡½æ•°

#### `xyz_quat_to_mat(xyz, quat)`

å°†ä½ç½®å’Œå››å…ƒæ•°è½¬æ¢ä¸º4x4å˜æ¢çŸ©é˜µã€‚

**å‚æ•°ï¼š**

- `xyz` (list): ä½ç½®å‘é‡ [x, y, z]
- `quat` (list): å››å…ƒæ•° [x, y, z, w]

**è¿”å›å€¼ï¼š** 4x4å˜æ¢çŸ©é˜µ (numpy.ndarray)

**ç¤ºä¾‹ï¼š**

```python
import numpy as np
from sdk.common import xyz_quat_to_mat

# åˆ›å»ºå˜æ¢çŸ©é˜µ
position = [1, 2, 3]
quaternion = [0, 0, 0, 1]  # å•ä½å››å…ƒæ•°

transform_matrix = xyz_quat_to_mat(position, quaternion)
print(f"å˜æ¢çŸ©é˜µ:\n{transform_matrix}")
```

#### `xyz_rot_to_mat(xyz, rot)`
å°†ä½ç½®å’Œæ—‹è½¬çŸ©é˜µè½¬æ¢ä¸º4x4å˜æ¢çŸ©é˜µã€‚

**å‚æ•°ï¼š**
- `xyz` (list): ä½ç½®å‘é‡ [x, y, z]
- `rot` (numpy.ndarray): 3x3æ—‹è½¬çŸ©é˜µ

**è¿”å›å€¼ï¼š** 4x4å˜æ¢çŸ©é˜µ

**ç¤ºä¾‹ï¼š**

```python
import numpy as np
from sdk.common import xyz_rot_to_mat

# åˆ›å»ºæ—‹è½¬çŸ©é˜µï¼ˆç»•Zè½´æ—‹è½¬90åº¦ï¼‰
rotation_matrix = np.array([
    [0, -1, 0],
    [1, 0, 0],
    [0, 0, 1]
])

position = [1, 2, 3]
transform_matrix = xyz_rot_to_mat(position, rotation_matrix)
```

#### `xyz_euler_to_mat(xyz, euler, degrees=True)`

å°†ä½ç½®å’Œæ¬§æ‹‰è§’è½¬æ¢ä¸º4x4å˜æ¢çŸ©é˜µã€‚

**å‚æ•°ï¼š**

- `xyz` (list): ä½ç½®å‘é‡ [x, y, z]
- `euler` (list): æ¬§æ‹‰è§’ [roll, pitch, yaw]
- `degrees` (bool): æ¬§æ‹‰è§’æ˜¯å¦ä¸ºåº¦æ•°ï¼Œé»˜è®¤True

**è¿”å›å€¼ï¼š** 4x4å˜æ¢çŸ©é˜µ

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import xyz_euler_to_mat

# ä½¿ç”¨åº¦æ•°
position = [1, 2, 3]
euler_angles = [0, 0, 90]  # 90åº¦åèˆªè§’
mat1 = xyz_euler_to_mat(position, euler_angles, degrees=True)

# ä½¿ç”¨å¼§åº¦
import math
euler_radians = [0, 0, math.pi/2]
mat2 = xyz_euler_to_mat(position, euler_radians, degrees=False)
```

#### `mat_to_xyz_euler(mat, degrees=True)`

ä»4x4å˜æ¢çŸ©é˜µæå–ä½ç½®å’Œæ¬§æ‹‰è§’ã€‚

**å‚æ•°ï¼š**

- `mat` (numpy.ndarray): 4x4å˜æ¢çŸ©é˜µ
- `degrees` (bool): è¿”å›çš„æ¬§æ‹‰è§’æ˜¯å¦ä¸ºåº¦æ•°ï¼Œé»˜è®¤True

**è¿”å›å€¼ï¼š** å…ƒç»„ (ä½ç½®å‘é‡, æ¬§æ‹‰è§’)

**ç¤ºä¾‹ï¼š**

```python
from sdk.common import mat_to_xyz_euler

# ä»å˜æ¢çŸ©é˜µæå–ä¿¡æ¯
xyz, euler = mat_to_xyz_euler(transform_matrix, degrees=True)
print(f"ä½ç½®: {xyz}")
print(f"æ¬§æ‹‰è§’: {euler}")

# åœ¨æœºå™¨äººä½å§¿ä¼°è®¡ä¸­ä½¿ç”¨
robot_pose_matrix = get_robot_pose_matrix()
position, orientation = mat_to_xyz_euler(robot_pose_matrix)
```

## ğŸ’¡ ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´çš„å›¾åƒå¤„ç†æµç¨‹

```python
import cv2
import numpy as np
from sdk.common import (
    cv2_image2ros, get_area_max_contour, plot_one_box,
    Colors, distance, box_center
)

def process_image(image):
    """å®Œæ•´çš„å›¾åƒå¤„ç†ç¤ºä¾‹"""
    # 1. å›¾åƒé¢„å¤„ç†
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # 2. è¾¹ç¼˜æ£€æµ‹
    edges = cv2.Canny(blurred, 50, 150)
    
    # 3. æŸ¥æ‰¾è½®å»“
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # 4. è·å–æœ€å¤§è½®å»“
    max_contour, area = get_area_max_contour(contours, threshold=100)
    
    if max_contour is not None:
        # 5. è·å–è¾¹ç•Œæ¡†
        x, y, w, h = cv2.boundingRect(max_contour)
        bbox = [x, y, x+w, y+h]
        
        # 6. è®¡ç®—ä¸­å¿ƒç‚¹
        center = box_center(bbox)
        
        # 7. ç»˜åˆ¶ç»“æœ
        colors = Colors()
        plot_one_box(bbox, image, color=colors(0), label=f"Area: {area:.0f}")
        cv2.circle(image, (int(center[0]), int(center[1])), 5, (0, 255, 0), -1)
    
    # 8. è½¬æ¢ä¸ºROSæ ¼å¼
    ros_image = cv2_image2ros(image, "camera_frame")
    
    return image, ros_image
```

### æœºå™¨äººå§¿æ€æ§åˆ¶ç¤ºä¾‹

```python
import math
import numpy as np
from sdk.common import (
    qua2rpy, rpy2qua, xyz_euler_to_mat, 
    mat_to_xyz_euler, distance
)

class RobotPoseController:
    def __init__(self):
        self.current_pose = None
    
    def set_target_pose(self, x, y, z, roll, pitch, yaw):
        """è®¾ç½®ç›®æ ‡ä½å§¿"""
        # åˆ›å»ºç›®æ ‡å˜æ¢çŸ©é˜µ
        target_matrix = xyz_euler_to_mat([x, y, z], [roll, pitch, yaw])
        return target_matrix
    
    def get_pose_error(self, current_matrix, target_matrix):
        """è®¡ç®—ä½å§¿è¯¯å·®"""
        # æå–ä½ç½®å’Œå§¿æ€
        current_pos, current_euler = mat_to_xyz_euler(current_matrix)
        target_pos, target_euler = mat_to_xyz_euler(target_matrix)
        
        # è®¡ç®—ä½ç½®è¯¯å·®
        pos_error = distance(current_pos, target_pos)
        
        # è®¡ç®—è§’åº¦è¯¯å·®
        angle_error = abs(current_euler[2] - target_euler[2])  # åèˆªè§’è¯¯å·®
        
        return pos_error, angle_error
    
    def control_loop(self, target_pose):
        """æ§åˆ¶å¾ªç¯"""
        while True:
            # è·å–å½“å‰ä½å§¿
            current_matrix = self.get_current_pose_matrix()
            
            # è®¡ç®—è¯¯å·®
            pos_error, angle_error = self.get_pose_error(current_matrix, target_pose)
            
            # æ£€æŸ¥æ˜¯å¦åˆ°è¾¾ç›®æ ‡
            if pos_error < 0.01 and angle_error < 0.01:
                print("åˆ°è¾¾ç›®æ ‡ä½å§¿")
                break
            
            # æ‰§è¡Œæ§åˆ¶å‘½ä»¤
            self.execute_control_command(pos_error, angle_error)
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. æ€§èƒ½ä¼˜åŒ–

```python
# é¿å…é‡å¤è®¡ç®—
colors = Colors()  # åˆ›å»ºä¸€æ¬¡ï¼Œé‡å¤ä½¿ç”¨

# ä½¿ç”¨numpyå‘é‡åŒ–æ“ä½œ
points = np.array([[x1, y1], [x2, y2], [x3, y3]])
distances = np.linalg.norm(points, axis=1)
```

### 2. é”™è¯¯å¤„ç†

```python
def safe_image_conversi
